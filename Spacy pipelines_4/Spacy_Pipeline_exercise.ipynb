{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6addcb05-843d-4fb0-83d4-db215c98cd81",
   "metadata": {},
   "source": [
    "Spacy Language Processing Pipelines: Exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e38fa7f-3523-4f44-8034-2b3470823a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  #creating an object and loading the pre-trained model for \"English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0871a369-dc14-4058-9834-3ad08edd001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73b7be37-593a-48a5-b331-8c416fec3948",
   "metadata": {},
   "source": [
    "Excersie: 1\n",
    "\n",
    "Get all the proper nouns from a given text in a list and also count how many of them.\n",
    "Proper Noun means a noun that names a particular person, place, or thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894a0fc7-6054-4195-bca9-2beeb5f57520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[Raju, Paris, London, Dubai, Rome, Mohan, Hyderabad]\n"
     ]
    }
   ],
   "source": [
    "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''\n",
    "\n",
    "#creating the nlp object\n",
    "doc = nlp(text)\n",
    "count = 0\n",
    "noun=[]\n",
    "for token in doc:\n",
    "    if token.pos_ ==\"PROPN\":\n",
    "        count= count+1\n",
    "        noun.append(token)\n",
    "print(count)\n",
    "print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd039976-c0d2-41c1-aa7f-e573502fbaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ravi | NOUN | noun\n",
      "and | CCONJ | coordinating conjunction\n",
      "Raju | PROPN | proper noun\n",
      "are | AUX | auxiliary\n",
      "the | DET | determiner\n",
      "best | ADJ | adjective\n",
      "friends | NOUN | noun\n",
      "from | ADP | adposition\n",
      "school | NOUN | noun\n",
      "days | NOUN | noun\n",
      ". | PUNCT | punctuation\n",
      "They | PRON | pronoun\n",
      "wanted | VERB | verb\n",
      "to | PART | particle\n",
      "go | VERB | verb\n",
      "for | ADP | adposition\n",
      "a | DET | determiner\n",
      "world | NOUN | noun\n",
      "tour | NOUN | noun\n",
      "and | CCONJ | coordinating conjunction\n",
      "\n",
      " | SPACE | space\n",
      "visit | VERB | verb\n",
      "famous | ADJ | adjective\n",
      "cities | NOUN | noun\n",
      "like | ADP | adposition\n",
      "Paris | PROPN | proper noun\n",
      ", | PUNCT | punctuation\n",
      "London | PROPN | proper noun\n",
      ", | PUNCT | punctuation\n",
      "Dubai | PROPN | proper noun\n",
      ", | PUNCT | punctuation\n",
      "Rome | PROPN | proper noun\n",
      "etc | X | other\n",
      "and | CCONJ | coordinating conjunction\n",
      "also | ADV | adverb\n",
      "they | PRON | pronoun\n",
      "called | VERB | verb\n",
      "their | PRON | pronoun\n",
      "another | DET | determiner\n",
      "friend | NOUN | noun\n",
      "Mohan | PROPN | proper noun\n",
      "to | PART | particle\n",
      "take | VERB | verb\n",
      "part | NOUN | noun\n",
      "of | ADP | adposition\n",
      "this | DET | determiner\n",
      "world | NOUN | noun\n",
      "tour | NOUN | noun\n",
      ". | PUNCT | punctuation\n",
      "\n",
      " | SPACE | space\n",
      "They | PRON | pronoun\n",
      "started | VERB | verb\n",
      "their | PRON | pronoun\n",
      "journey | NOUN | noun\n",
      "from | ADP | adposition\n",
      "Hyderabad | PROPN | proper noun\n",
      "and | CCONJ | coordinating conjunction\n",
      "spent | VERB | verb\n",
      "next | ADJ | adjective\n",
      "3 | NUM | numeral\n",
      "months | NOUN | noun\n",
      "travelling | VERB | verb\n",
      "all | DET | determiner\n",
      "the | DET | determiner\n",
      "wonderful | ADJ | adjective\n",
      "cities | NOUN | noun\n",
      "in | ADP | adposition\n",
      "the | DET | determiner\n",
      "world | NOUN | noun\n",
      "and | CCONJ | coordinating conjunction\n",
      "cherish | VERB | verb\n",
      "a | DET | determiner\n",
      "happy | ADJ | adjective\n",
      "moments | NOUN | noun\n",
      "! | PUNCT | punctuation\n",
      "\n",
      " | SPACE | space\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \"|\", token.pos_, \"|\", spacy.explain(token.pos_))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccd09c33-28a0-467b-a26a-5b6b77adc6c6",
   "metadata": {},
   "source": [
    "Excersie: 2\n",
    "\n",
    "Get all companies names from a given text and also the count of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eded02b-6158-4780-bf6b-40696f817bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[Tesla, Walmart, Amazon, Microsoft, Google, Infosys, Reliance, HDFC Bank, Hindustan Unilever, Bharti Airtel]\n"
     ]
    }
   ],
   "source": [
    "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in \n",
    "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
    "\n",
    "\n",
    "doc = nlp(text)\n",
    "count = 0\n",
    "company = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_=='ORG':\n",
    "        company.append(ent)\n",
    "        count = count+1\n",
    "print(count)\n",
    "print(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b40f511-4d70-4572-a491-b5565e8f5a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 CARDINAL\n",
      "USA GPE\n",
      "Tesla ORG\n",
      "Walmart ORG\n",
      "Amazon ORG\n",
      "Microsoft ORG\n",
      "Google ORG\n",
      "5 CARDINAL\n",
      "India GPE\n",
      "Infosys ORG\n",
      "Reliance ORG\n",
      "HDFC Bank ORG\n",
      "Hindustan Unilever ORG\n",
      "Bharti Airtel ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c16abc-3c82-4be6-8427-f25a78a834d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
